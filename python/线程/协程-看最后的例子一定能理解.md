[原文](http://python.jobbole.com/86069/)

# Python协程：从yield/send到async/await

Python 由于众所周知的 GIL 的原因，导致其线程无法发挥多核的并行计算能力（当然，后来有了 `multiprocessing` ，可以实现多进程并行），显得比较鸡肋。

既然在 GIL 之下，同一时刻只能有一个线程在运行，
那么对于 ==CPU 密集的程序== 来说，<u>**线程之间的切换**</u> 开销就成了拖累。

而以 I/O 为瓶颈的程序正是 **协程所擅长的**：
<u>多任务并发（非并行），
每个任务在合适的时候 ==挂起==(发起I/O）和 ==恢复==(结束I/O)</u>


# Python中的协程发展历程
其大概经历了如下三个阶段：
1. 最初的生成器变形 **`yield`**/**`send`** 
2. 引入 **`@asyncio.coroutine`** 和 **`yield from`**
3. 在最近的 Python3.5 版本中引入 **`async`**/**`await`** 关键字，代替`@asyncio.coroutine` 和 `yield from `
<br>

## yield 生成器
先看一段普通的计算 **斐波那契续列** 的代码：
```py
def old_fib(n):
    res = [0] * n
    idx = 0
    a = 0
    b = 1
    while idx < n:
        res[idx] = b
        a, b = b, a + b
        idx += 1
    return res

for fib_res in old_fib(20):
    print(fib_res)
```
如果我们仅仅是需要拿到斐波那契序列的第n位，或者仅仅是希望依此产生斐波那契序列，那么上面这种传统方式就会比较耗费内存。

这时，yield就派上用场了。
```py
def fib(n):             # 生成器
    idx = 0
    a = 0
    b = 1
    while idx < n:
        yield b         # 保留 fib 函数的计算现场，暂停 fib 的计算并将 b 返回
        a, b = b, a + b
        idx += 1

# (迭代) next
for fib_res in fib(20): # fib(20): 生成器对象实例 
    print(fib_res)
```
==当一个函数中包含 yield 语句时， python 会自动将其识别为一个生成器==。
这时 `fib(20)` 并不会真正调用函数体，而是以函数体生成了一个生成器对象实例。

yield 在这里可以保留 fib 函数的计算现场，暂停 fib 的计算并将 b 返回。
**<u>而将 fib 放入 for in 循环中时，每次循环都会调用 `next(fib(20))`，唤醒生成器，执行到下一个 yield 语句处，直到抛出 `StopIteration` 异常。</u>
<u>此异常会被 for 循环捕获，导致跳出循环。</u>**
<br>

## Send（发送数据
从上面的程序中可以看到，目前只有数据从 `fib(20)` 中通过 `yield` 流向外面的 for 循环；
如果可以 <u>**向 `fib(20)` 发送数据**</u>，那不是就可以在 Python 中实现协程了嘛。

于是， Python 中的生成器有了 send 函数， yield 表达式也拥有了返回值。 

我们用这个特性，模拟一个额 **慢速斐波那契数列** 的计算：
```py
def stupid_fib(n):
    idx = 0
    a = 0
    b = 1
    while idx < n:
        sleep_cnt = yield b     # 接收外界发送的数据
        print('let me think {0} secs'.format(sleep_cnt))
        time.sleep(sleep_cnt)
        a, b = b, a + b
        idx += 1

N = 20
sfib = stupid_fib(N)    # sfib: stupid_fib 生成器
fib_res = next(sfib)    # 相当于 sfib.send(None)
while True:
    print(fib_res)
    try:
        # 将一个随机的秒数发送给 sfib, 作为当前中断的 yield 表达式的返回值
        fib_res = sfib.send(random.uniform(0, 0.5)) 
    except StopIteration:
        break
```
**其中 `next(sfib)` 相当于 `sfib.send(None)`**，可以使得 sfib 运行至第一个 yield 处返回。
后续的 `sfib.send(random.uniform(0, 0.5))` 则将一个随机的秒数发送给 sfib, 作为当前中断的 yield 表达式的返回值。

这样，我们可以从“主”程序中控制协程计算斐波那契数列时的思考时间，协程可以返回给“主”程序计算结果， Perfect！
<br>

## yield from（重构生成器
yield from 用于 **复制生成器**，简单的，可以这么使用：
```py
def copy_fib(n):
    print('I am copy from fib')
    yield from fib(n)   # 复制生成器
    print('Copy end')

for fib_res in copy_fib(20):
    print(fib_res)
```
这种使用方式很简单，但远远不是 yield from 的全部。 

yield from 的作用还体现在：
<u>可以像一个 **管道** 一样将 send 信息传递给内层协程，并且处理好了各种异常情况。</u>

因此，对于 stupid_fib 也可以这样包装和使用：
```py
def copy_stupid_fib(n):
    print('I am copy from stupid fib')
    yield from stupid_fib(n)    # stupid_fib 能够接收数据的生成器
    print('Copy end')

N = 20
csfib = copy_stupid_fib(N)  # csfib: copy_stupid_fib 生成器
fib_res = next(csfib)       # 相当于 csfib.send(None) 启动生成器
while True:
    print(fib_res)
    try:
        # 传递数据
        fib_res = csfib.send(random.uniform(0, 0.5))
    except StopIteration:
        break
```
如果没有 `yield from`，这里的 copy_yield_from 将会特别复杂（因为要自己处理各种异常）。
<br>

### asyncio.coroutine

`yield from` 在 `asyncio` 模块中得以发扬光大。先看示例代码：
```py
@asyncio.coroutine  # 装饰器 可以协程的控制权交给事件循环
def smart_fib(n):
    idx = 0
    a = 0
    b = 1
    while idx < n:
        sleep_secs = random.uniform(0, 0.2) # 随机数
        # 通过 yield from ，将协程 asyncio.sleep 的控制权交给事件循环，然后挂起当前协程；
        yield from asyncio.sleep(sleep_secs)
        print('Smart one think {} secs to get {}'.format(sleep_secs, b))
        a, b = b, a + b
        idx += 1


@asyncio.coroutine
def stupid_fib(n):
    idx = 0
    a = 0
    b = 1
    while idx < n:
        sleep_secs = random.uniform(0, 0.4)
        # 通过 yield from ，将协程 asyncio.sleep 的控制权交给事件循环，然后挂起当前协程；
        yield from asyncio.sleep(sleep_secs) 
        print('Stupid one think {} secs to get {}'.format(sleep_secs, b))
        a, b = b, a + b
        idx += 1


if __name__ == '__main__':
    # 之后，由事件循环决定何时唤醒协程 asyncio.sleep, 接着向后执行代码。
    loop = asyncio.get_event_loop()
    tasks = [
        asyncio.async(smart_fib(10)),   # 两个任务
        asyncio.async(stupid_fib(10)),
    ]
    loop.run_until_complete(asyncio.wait(tasks))
    print('All fib finished.')
    loop.close()
```
`asyncio` 是一个 <u>基于事件循环</u> 的 **实现异步 I/O 的模块**。

==通过 `yield from` ，将协程 `asyncio.sleep` 的控制权交给事件循环，然后挂起当前协程；
之后，由事件循环决定何时唤醒 `asyncio.sleep`, 接着向后执行代码。==

这样说可能比较抽象，好在 `asyncio` 是一个由 python 实现的模块，那么我们来看看 `asyncio.sleep` 中都做了些什么：
```py
@coroutine
def sleep(delay, result=None, *, loop=None):
    """ 
    Coroutine that completes after a given time (in seconds).
    """
    future = futures.Future(loop=loop)  # 创建 Future 对象，作为更内层的协程对象
    # 通过调用事件循环的 call_later 函数，注册了一个回调函数
    h = future._loop.call_later(delay, future._set_result_unless_cancelled, result)
    try:
        return (yield from future)  # 将 Future 对象 通过 yield from 交给事件循环
    finally:
        h.cancel()
```
首先，sleep 创建了一个 `Future` 对象，作为更内层的协程对象，
通过 `yield from` 交给了事件循环；
其次，它通过调用事件循环的 `call_later` 函数，注册了一个回调函数。

通过查看 Future 类的源码，可以看到，
<u>**`Future` 是一个实现了 `__iter__` 对象的生成器**</u>：
```py
class Future:
    # blabla...
    def __iter__(self):
        if not self.done():
            self._blocking = True
            yield self          # This tells Task to wait for completion.
        assert self.done(), "yield from wasn't used with future"
        return self.result()    # May raise too.

```
那么当我们的协程 `yield from asyncio.sleep` 时，<u>事件循环</u> 其实是与 <u>Future 对象</u> 建立了联系。
- 每次事件循环调用 `send(None)` 时，其实都会传递到 Future 对象的 `__iter__` 函数调用；
- 而当 Future 尚未执行完毕的时候，就会 `yield self` ，也就意味着暂时挂起，等待下一次 `send(None)` 的唤醒。 

当我们包装一个 Future 对象产生一个 Task 对象时，在 Task 对象初始化中，就会调用 Future 的 send(None), 并且为 Future 设置好回调函数。
```py
class Task(futures.Future):
    # blabla...
    def _step(self, value=None, exc=None):
        # blabla...
        try:
            if exc is not None:
                result = coro.throw(exc)
            elif value is not None:
                result = coro.send(value)
            else:
                result = next(coro)
        # exception handle
        else:
            if isinstance(result, futures.Future):
                # Yielded Future must come from Future.__iter__().
                if result._blocking:
                    result._blocking = False
                    result.add_done_callback(self._wakeup)
        # blabla...

    def _wakeup(self, future):
        try:
            value = future.result()
        except Exception as exc:
            # This may also be a cancellation.
            self._step(None, exc)
        else:
            self._step(value, None)
        self = None  # Needed to break cycles when an exception occurs.
```
预设的时间过后，事件循环将调用 `Future._set_result_unless_cancelled`:
```py
class Future:
    #blabla...
    def _set_result_unless_cancelled(self, result):
        """Helper setting the result only if the future was not cancelled."""
        if self.cancelled():
            return
        self.set_result(result)

    def set_result(self, result):
        """Mark the future done and set its result.

        If the future is already done when this method is called, raises
        InvalidStateError.
        """
        if self._state != _PENDING:
            raise InvalidStateError('{}: {!r}'.format(self._state, self))
        self._result = result
        self._state = _FINISHED
        self._schedule_callbacks()
```
这将改变 Future 的状态，同时回调之前设定好的 Tasks._wakeup ；
在 _wakeup 中，将会再次调用 Tasks._step，这时，Future 的状态已经标记为完成，因此，将不再 yieldself ，
而 return 语句将会触发一个 StopIteration 异常，此异常将会被 Task._step 捕获用于设置 Task 的结果。
同时，整个 yield from 链条也将被唤醒，协程将继续往下执行。
<br>

## async 和 await
弄清楚了 **<u>`asyncio.coroutine`(将协程交给事件循环)</u>** 和 **<u>`yield from`(复制生成器)</u>** 之后，
再 Python3.5 中引入的 ==**async (异步函数, 将协程交给事件循环)**== 和 ==**await (复制生成器)**== 就不难理解了：
<u>可以将他们理解成 `asyncio.coroutine` / `yield from` 的完美替身。</u>
<br>

当然，从 Python 设计的角度来说， 
<u>`async` / `await` 让协程表面上独立于生成器而存在，
将细节都隐藏于 asyncio 模块之下，语法更清晰明了。</u>
```py
async def smart_fib(n):
    idx = 0
    a = 0
    b = 1
    while idx < n:
        sleep_secs = random.uniform(0, 0.2)
        # 通过 await ，将协程 asyncio.sleep 的控制权交给事件循环，然后挂起当前协程；
        await asyncio.sleep(sleep_secs)
        print('Smart one think {} secs to get {}'.format(sleep_secs, b))
        a, b = b, a + b
        idx += 1


async def stupid_fib(n):
    idx = 0
    a = 0
    b = 1
    while idx < n:
        sleep_secs = random.uniform(0, 0.4)
        # 通过 await ，将协程 asyncio.sleep 的控制权交给事件循环，然后挂起当前协程；
        await asyncio.sleep(sleep_secs)
        print('Stupid one think {} secs to get {}'.format(sleep_secs, b))
        a, b = b, a + b
        idx += 1


if __name__ == '__main__':
    # 通过 await ，将协程 asyncio.sleep 的控制权交给事件循环，然后挂起当前协程；
    # 之后，由事件循环决定何时唤醒 asyncio.sleep, 接着向后执行代码。
    loop = asyncio.get_event_loop()
    tasks = [
        asyncio.ensure_future(smart_fib(10)),
        asyncio.ensure_future(stupid_fib(10)),
    ]
    loop.run_until_complete(asyncio.wait(tasks))
    print('All fib finished.')
    loop.close()
```
<br>

## 总结
至此， Python 中的协程就介绍完毕了。
示例程序中都是以 sleep 为异步 I/O 的代表，
在实际项目中，可以使用协程异步的 **读写网络、读写文件、渲染界面** 等，
<u>而在等待协程完成的同时，CPU 还可以进行其他的计算。</u>
协程的作用正在于此。


# 简单应用
[出处：廖雪峰教程](https://www.liaoxuefeng.com/wiki/1016959663602400/1017968846697824)

在学习异步 IO 模型前，我们先来了解协程。 
协程，又称微线程，纤程。英文名 Coroutine。 
协程的概念很早就提出来了，但直到最近几年才在某些语言（如 Lua）中得到广泛应用。 

- **子程序**，或者称为函数。
    - 在所有语言中都是层级调用，比如 A 调用 B ， B 在执行过程中又调用了 C ， C 执行完毕返回， B 执行完毕返回，最后是 A 执行完毕。 
    - 所以子程序调用是通过栈实现的，一个线程就是执行一个子程序。 
    - 子程序调用总是一个入口，一次返回，调用顺序是明确的。

- **协程** 的调用和子程序不同。
    - <u>协程看上去也是子程序</u>，==但执行过程中，在子程序内部可中断，然后转而执行别的子程序，在适当的时候再返回来接着执行。==
    - 注意，在一个子程序中中断，去执行其他子程序，不是函数调用，有点<u>类似 CPU 的中断</u>。

比如子程序 A 、 B ：
```py
def A():
    print('1')
    print('2')
    print('3')

def B():
    print('x')
    print('y')
    print('z')
```
<u>假设由协程执行，在执行 A 的过程中，可以随时中断，去执行 B，B 也可能在执行过程中中断再去执行 A</u> ，结果可能是：
```
1
2
x
y
3
z
```
但是在 A 中是没有调用 B 的，所以协程的调用比函数调用理解起来要难一些。 
看起来 A 、 B 的执行有点像多线程，
但协程的特点在于是 ==**一个线程执行**==。
- **那和多线程比，协程有何优势**？ 
    - 最大的优势就是协程<u>极高的执行效率</u>。
    因为子程序切换不是线程切换，而是由程序自身控制，因此，没有线程切换的开销，和多线程比，线程数量越多，协程的性能优势就越明显。 
    - 第二大优势就是<u>不需要多线程的锁机制</u>，因为只有一个线程，也不存在同时写变量冲突，在协程中控制共享资源不加锁，只需要判断状态就好了，所以执行效率比多线程高很多。 
    <br>


- **因为协程是一个线程执行，那怎么利用多核 CPU 呢**？
最简单的方法是<u>多进程 + 协程</u>，既充分利用多核，又充分发挥协程的高效率，可获得极高的性能。 
<br>

<u>**Python 对协程的支持是通过 生成器 generator 实现的**。</u>
在 generator 中，我们不但可以通过 for 循环来迭代，还可以不断调用 next() 函数获取由 yield 语句返回的下一个值。 
但是 ==Python 的 yield 不但可以返回一个值，它还可以接收调用者发出的参数==。
<br>


## 例子，生产者 - 消费者模型
是一个线程写消息，一个线程取消息，通过锁机制控制队列和等待，但一不小心就可能死锁。 
如果改用协程，
<u>生产者生产消息后，==直接通过 yield 跳转到消费者开始执行==，
待消费者执行完毕后，切换回生产者继续生产，效率极高</u>：
```py
def consumer():         # 消费者 生成器
    ret = ''            # ret: 传递给外界的结果
    while True:         # while True 表此生成器在遍历使用时可以循环无限次
        n = yield ret   # n: 接收调用者传递的参数 ret: 由上一层循环得到的字符串 '200 OK'
        if not n:
            return      # return 表不继续往下执行 print 不是返回值出去的意思
        print('[CONSUMER] Consuming %s...' % n) # 【消费】
        ret = '200 OK'

# 边生产边消费
def produce(c):         # 生产者 不是生成器
    c.send(None)        # 启动 consumer 消费者生成器
    n = 0
    while n < 5:
        n = n + 1       # 【生产】
        print('[PRODUCER] Producing %s...' % n)
        ret = c.send(n)     # consumer 生成器接收数据 返回处理后的值
        print('[PRODUCER] Consumer return: %s' % ret)
        print('----------------------------')
    c.close()               # 关闭 consumer 生成器

c = consumer()
produce(c)

# 执行结果：
# [PRODUCER] Producing 1...
# [CONSUMER] Consuming 1...
# [PRODUCER] Consumer return: 200 OK
# ----------------------------
# [PRODUCER] Producing 2...
# [CONSUMER] Consuming 2...
# [PRODUCER] Consumer return: 200 OK
# ----------------------------
# [PRODUCER] Producing 3...
# [CONSUMER] Consuming 3...
# [PRODUCER] Consumer return: 200 OK
# ----------------------------
# [PRODUCER] Producing 4...
# [CONSUMER] Consuming 4...
# [PRODUCER] Consumer return: 200 OK
# ----------------------------
# [PRODUCER] Producing 5...
# [CONSUMER] Consuming 5...
# [PRODUCER] Consumer return: 200 OK
# ----------------------------
```
注意： consumer 函数是一个 generator ，
把一个 consumer 传入 produce 后： 
- 首先调用 `c.send(None)` 启动生成器； 
- 然后，一旦生产了东西，
    - 通过 `c.send(n)` 切换到 consumer 执行； 
    - consumer 通过 `yield` 拿到消息，处理，又通过 `yield` 把结果传回； 
    - produce 拿到 consumer 处理的结果，继续生产下一条消息； 
- produce 决定不生产了，通过 `c.close()` 关闭 consumer ，整个过程结束。 

整个流程无锁，由一个线程执行， 
==produce 和 consumer 协作完成任务，所以称为“协程”==，而非线程的抢占式多任务。 

最后套用 Donald Knuth 的一句话总结协程的特点： <u>“子程序就是协程的一种特例。”</u>







